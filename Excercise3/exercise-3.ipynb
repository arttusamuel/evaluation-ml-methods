{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TKO_7092 Evaluation of Machine Learning Methods 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Student name: Arttu Kuitunen\n",
    "\n",
    "Student number: 1500155\n",
    "\n",
    "Student email: arsaku@utu.fi\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "\n",
    "Complete the tasks given to you in the letter below. In your submission, explain clearly, precisely, and comprehensively why the cross-validation described in the letter failed, what is the correct way to perform cross-validation in the given scenario, and why the correct cross-validation method will give a reliable estimate of the generalisation performance. Then implement the correct cross-validation for the scenario and report its results.\n",
    "\n",
    "Remember to follow all the general exercise guidelines that are stated in Moodle. Full points (2p) will be given for a submission that demonstrates a deep understanding of cross-validation on pair-input data and implements the requested cross-validation correctly (incl. reporting the results). Partial points (1p) will be given if there are small error(s) but the overall approach is correct. No points will be given if there are significant error(s).\n",
    "\n",
    "The deadline of this exercise is **Wednesday 19 February 2025 at 11:59 PM**. Please contact Juho Heimonen (juaheim@utu.fi) if you have any questions about this exercise.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dear Data Scientist,\n",
    "\n",
    "I have a long-term research project regarding a specific set of proteins. I am attempting to discover small organic compounds that can bind strongly to these proteins and thus act as drugs. I have already made laboratory experiments to measure the affinities between some proteins and drug molecules.\n",
    "\n",
    "My colleague is working on another set of proteins, and the objectives of his project are similar to mine. He has recently discovered thousands of new potential drug molecules. He asked me if I could find the pairs that have the strongest affinities among his proteins and drug molecules. Obviously I do not have the resources to measure all the possible pairs in my laboratory, so I need to prioritise. I decided to do this with the help of machine learning, but I have encountered a problem.\n",
    "\n",
    "Here is what I have done so far: First I trained a K-nearest neighbours regressor with the parameter value K=10 using all the 400 measurements I had already made in the laboratory with my proteins and drug molecules. They comprise of 77 target proteins and 59 drug molecules. Then I performed a leave-one-out cross-validation with this same data to estimate the generalisation performance of the model. I used C-index and got a stellar score above 90%. Finally I used the model to predict the affinities of my colleague's proteins and drug molecules. The problem is: when I selected the highest predicted affinities and tried to verify them in the lab, I found that many of them are much lower in reality. My model clearly does not work despite the high cross-validation score.\n",
    "\n",
    "Please explain why my estimation failed and how leave-one-out cross-validation should be performed to get a reliable estimate. Also, implement the correct leave-one-out cross-validation and report its results. I need to know whether it would be a waste of my resources if I were to use my model any further.\n",
    "\n",
    "The data I used to create my model is available in the files `input.data`, `output.data` and `pairs.data` for you to use. The first file contains the features of the pairs, whereas the second contains their affinities. The third file contains the identifiers of the drug and target molecules of which the pairs are composed. The files are paired, i.e. the i<sup>*th*</sup> row in each file is about the same pair.\n",
    "\n",
    "Looking forward to hearing from you soon.\n",
    "\n",
    "Yours sincerely, \\\n",
    "Bio Scientist\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer the questions about cross-validation on pair-input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why did the estimation described in the letter fail?\n",
    "\n",
    "## Biggest problem is that the data set has not been divided in to training and test sets.\n",
    "## This will overfit the model to the training data (in this case the entire data set) \n",
    "## and will not be able to generalize as well as the c_index results indicate. There is also data leakage \n",
    "\n",
    "## Pair-input data evaluation should be done for all types of out-of-sample data. \n",
    "## A, B, C and D where a has dependencies on both inputs, B and C only share \n",
    "## dependencie for one of the inputs and D that is independent from both pair-inputs. \n",
    "## Then we get a better estimate of the models performance, since we cannot assume \n",
    "## the data to be independent as we could with single observations. \n",
    "\n",
    "## In this example, pair-input data is not properly handled in training. \n",
    "\n",
    "\n",
    "# How should leave-one-out cross-validation be performed in the given scenario and why?\n",
    "\n",
    "## Cross-validation could be performed to choose the best hyperparameters for the model. Now there is only k=10 tested.\n",
    "\n",
    "# Remember to provide comprehensive and precise arguments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries you need.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import LeaveOneOut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the utility functions you need in your analysis.\n",
    "def cindex(y, yp):\n",
    "    \"\"\"Calculate concordance index\"\"\"\n",
    "    n = 0\n",
    "    h_num = 0 \n",
    "    for i in range(len(y)):\n",
    "        t = y[i]\n",
    "        p = yp[i]\n",
    "        for j in range(i+1, len(y)):\n",
    "            nt = y[j]\n",
    "            np = yp[j]\n",
    "            if t != nt:\n",
    "                n += 1\n",
    "                if (p < np and t < nt) or (p > np and t > nt):\n",
    "                    h_num += 1\n",
    "                elif p == np:\n",
    "                    h_num += 0.5\n",
    "    return h_num/n if n > 0 else 0\n",
    "\n",
    "def get_modified_training_sets(X, pairs_data, train_idx, test_idx):\n",
    "    \"\"\"\n",
    "    Create four different training sets for A, B, C, D scenarios based on dependencies\n",
    "    \"\"\"\n",
    "    # Get test pair information\n",
    "    test_protein = pairs_data.iloc[test_idx]['protein'].values[0]\n",
    "    test_drug = pairs_data.iloc[test_idx]['drug'].values[0]\n",
    "    \n",
    "    # Create masks for each scenario\n",
    "    mask_B = pairs_data.iloc[train_idx]['drug'] != test_drug\n",
    "    mask_C = pairs_data.iloc[train_idx]['protein'] != test_protein\n",
    "    mask_D = mask_B & mask_C\n",
    "    \n",
    "    # Get indices for each scenario\n",
    "    train_A = train_idx  # All training data\n",
    "    train_B = train_idx[mask_B]  # Remove pairs with test drug\n",
    "    train_C = train_idx[mask_C]  # Remove pairs with test protein\n",
    "    train_D = train_idx[mask_D]  # Remove pairs with either test protein or drug\n",
    "    \n",
    "    # Create training sets\n",
    "    training_sets = {\n",
    "        'A': X[train_A],\n",
    "        'B': X[train_B],\n",
    "        'C': X[train_C],\n",
    "        'D': X[train_D]\n",
    "    }\n",
    "    \n",
    "    indices = {\n",
    "        'A': train_A,\n",
    "        'B': train_B,\n",
    "        'C': train_C,\n",
    "        'D': train_D\n",
    "    }\n",
    "    \n",
    "    # Count samples in each set\n",
    "    counts = {\n",
    "        'A': len(train_A),\n",
    "        'B': len(train_B),\n",
    "        'C': len(train_C),\n",
    "        'D': len(train_D)\n",
    "    }\n",
    "    \n",
    "    return training_sets, indices, counts\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data files (input.data, output.data, pairs.data).\n",
    "# Load data\n",
    "input_data = pd.read_csv('input.data', header=None, sep=' ')\n",
    "output_data = pd.read_csv('output.data', header=None, sep=' ')\n",
    "pairs_data = pd.read_csv('pairs.data', header=None, sep=' ', names=['protein', 'drug'])\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X = input_data.values\n",
    "y = output_data.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0         1         2         3         4         5         6   \\\n",
      "0  0.759222  0.709585  0.253151  0.421082  0.727780  0.404487  0.709027   \n",
      "1  0.034584  0.304720  0.688257  0.296396  0.151878  0.830755  0.270656   \n",
      "2  0.737867  0.236079  0.905987  0.163612  0.801455  0.789823  0.393999   \n",
      "3  0.406913  0.607740  0.235365  0.888679  0.150347  0.598991  0.130108   \n",
      "4  0.697707  0.432565  0.650329  0.886065  0.328660  0.576926  0.523100   \n",
      "\n",
      "         7         8         9   ...        57        58        59        60  \\\n",
      "0  0.242963  0.407292  0.379971  ...  0.838616  0.165050  0.515334  0.332678   \n",
      "1  0.705392  0.186120  0.085594  ...  0.472762  0.730013  0.639373  0.445218   \n",
      "2  0.522067  0.411352  0.781861  ...  0.595468  0.582292  0.836193  0.281514   \n",
      "3  0.465818  0.799953  0.906878  ...  0.453880  0.311799  0.534668  0.563793   \n",
      "4  0.080463  0.131349  0.913496  ...  0.583892  0.444141  0.249423  0.110690   \n",
      "\n",
      "         61        62        63        64        65        66  \n",
      "0  0.577533  0.678125  0.463608  0.538938  0.460883  0.345251  \n",
      "1  0.455680  0.090737  0.308432  0.079023  0.603089  0.197008  \n",
      "2  0.791790  0.081695  0.583450  0.422539  0.076437  0.299662  \n",
      "3  0.727767  0.172686  0.908368  0.786892  0.790459  0.666388  \n",
      "4  0.420770  0.250148  0.196350  0.427255  0.166715  0.919720  \n",
      "\n",
      "[5 rows x 67 columns]\n",
      "          0\n",
      "0  0.733933\n",
      "1  0.569419\n",
      "2  0.832588\n",
      "3  0.389664\n",
      "4  0.725953\n",
      "  protein drug\n",
      "0     D40   T2\n",
      "1     D31  T64\n",
      "2      D6  T58\n",
      "3     D56  T49\n",
      "4     D20  T28\n"
     ]
    }
   ],
   "source": [
    "print(input_data.head())\n",
    "print(output_data.head())\n",
    "print(pairs_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement and run cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-validation results:\n",
      "\n",
      "Split type A:\n",
      "C-index = 0.830\n",
      "Average training set size: 399.0\n",
      "Number of predictions: 400\n",
      "\n",
      "Split type B:\n",
      "C-index = 0.830\n",
      "Average training set size: 393.7\n",
      "Number of predictions: 400\n",
      "\n",
      "Split type C:\n",
      "C-index = 0.520\n",
      "Average training set size: 392.4\n",
      "Number of predictions: 400\n",
      "\n",
      "Split type D:\n",
      "C-index = 0.522\n",
      "Average training set size: 387.1\n",
      "Number of predictions: 400\n"
     ]
    }
   ],
   "source": [
    "# Implement and run the requested cross-validation. Report and interpret its results.\n",
    "predictions = {'A': [], 'B': [], 'C': [], 'D': []}\n",
    "true_values = {'A': [], 'B': [], 'C': [], 'D': []}\n",
    "avg_train_sizes = {'A': 0, 'B': 0, 'C': 0, 'D': 0}\n",
    "total_iterations = 0\n",
    "\n",
    "# Perform leave-one-out cross-validation\n",
    "loo = LeaveOneOut()\n",
    "for train_idx, test_idx in loo.split(X):\n",
    "    X_test = X[test_idx]\n",
    "    y_test = y[test_idx]\n",
    "    total_iterations += 1\n",
    "    \n",
    "    # Get modified training sets for each scenario\n",
    "    training_sets, train_indices, counts = get_modified_training_sets(\n",
    "        X, pairs_data, train_idx, test_idx)\n",
    "    \n",
    "    # Update average training set sizes\n",
    "    for split_type in ['A', 'B', 'C', 'D']:\n",
    "        avg_train_sizes[split_type] += counts[split_type]\n",
    "    \n",
    "    # For each scenario (A, B, C, D)\n",
    "    for split_type in ['A', 'B', 'C', 'D']:\n",
    "        if len(train_indices[split_type]) > 0:\n",
    "            # Train model with modified training set\n",
    "            X_train = training_sets[split_type]\n",
    "            y_train = y[train_indices[split_type]]\n",
    "            \n",
    "            # Use min(10, len(y_train)) neighbors to handle small training sets\n",
    "            k = min(10, len(y_train))\n",
    "            model = KNeighborsRegressor(n_neighbors=k)\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Make prediction\n",
    "            pred = model.predict(X_test)[0]\n",
    "            \n",
    "            # Store prediction and true value\n",
    "            predictions[split_type].append(pred)\n",
    "            true_values[split_type].append(y_test[0])\n",
    "\n",
    "# Calculate average training set sizes\n",
    "for split_type in avg_train_sizes:\n",
    "    avg_train_sizes[split_type] = avg_train_sizes[split_type] / total_iterations\n",
    "\n",
    "# Print results\n",
    "print(\"\\nCross-validation results:\")\n",
    "for split_type in ['A', 'B', 'C', 'D']:\n",
    "    if len(predictions[split_type]) > 1:\n",
    "        c_idx = cindex(true_values[split_type], predictions[split_type])\n",
    "        print(f\"\\nSplit type {split_type}:\")\n",
    "        print(f\"C-index = {c_idx:.3f}\")\n",
    "        print(f\"Average training set size: {avg_train_sizes[split_type]:.1f}\")\n",
    "        print(f\"Number of predictions: {len(predictions[split_type])}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
